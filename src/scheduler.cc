/*************************************************************************\
 * AdapterRemoval - cleaning next-generation sequencing reads            *
 *                                                                       *
 * Copyright (C) 2015 by Mikkel Schubert - mikkelsch@gmail.com           *
 *                                                                       *
 * If you use the program, please cite the paper:                        *
 * S. Lindgreen (2012): AdapterRemoval: Easy Cleaning of Next Generation *
 * Sequencing Reads, BMC Research Notes, 5:337                           *
 * http://www.biomedcentral.com/1756-0500/5/337/                         *
 *                                                                       *
 * This program is free software: you can redistribute it and/or modify  *
 * it under the terms of the GNU General Public License as published by  *
 * the Free Software Foundation, either version 3 of the License, or     *
 * (at your option) any later version.                                   *
 *                                                                       *
 * This program is distributed in the hope that it will be useful,       *
 * but WITHOUT ANY WARRANTY; without even the implied warranty of        *
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the         *
 * GNU General Public License for more details.                          *
 *                                                                       *
 * You should have received a copy of the GNU General Public License     *
 * along with this program.  If not, see <http://www.gnu.org/licenses/>. *
\*************************************************************************/

#include <cerrno>
#include <cstdlib>
#include <iostream>
#include <queue>
#include <stdexcept>
#include <unistd.h>

#include "scheduler.h"


///////////////////////////////////////////////////////////////////////////////
// exceptions

thread_abort::thread_abort()
  : thread_error("abort thread")
{
}


///////////////////////////////////////////////////////////////////////////////
// analytical_chunk

analytical_chunk::analytical_chunk()
{
}

analytical_chunk::~analytical_chunk()
{
}


///////////////////////////////////////////////////////////////////////////////
// analytical_step

analytical_step::analytical_step(ordering step_order, bool file_io)
    : m_step_order(step_order)
    , m_file_io(file_io)
{
}

analytical_step::~analytical_step()
{
}


///////////////////////////////////////////////////////////////////////////////
// scheduler

struct data_chunk
{
    enum chunk_type {
        //! No data; used for initial chunks
        empty,
        //! Value generated by the pipeline
        value,
        //! Indicates the end of input data
        terminator
    };

    data_chunk(chunk_type type_ = empty,
               unsigned counter_ = 0,
               analytical_chunk* data_ = NULL)
      : type(type_)
      , counter(counter_)
      , data(data_)
    {
    }

    /** Sorts by counter, data, type, in that order. **/
    bool operator<(const data_chunk& other) const {
        if (counter > other.counter) {
            return true;
        } else if (counter == other.counter) {
            if (data > other.data) {
                return true;
            } else if (data == other.data) {
                return type > other.type;
            }
        }

        return false;
    }

    //! Chunk type; see above.
    chunk_type type;
    //! Strictly increasing counter; used to sort chunks for 'ordered' tasks
    unsigned counter;
    //! Use generated data; is not freed by this struct
    analytical_chunk* data;
};


struct scheduler_step
{
    scheduler_step(analytical_step* value)
      : lock()
      , ptr(value)
      , current_chunk(0)
      , queue()
    {
    }

    /** Deletes any remaining chunks. */
    ~scheduler_step() {
        reset();
    }

    /** Cleans up after previous runs; deleting any remaining chunks. */
    void reset() {
        while (!queue.empty()) {
            delete queue.top().data;
            queue.pop();
        }
    }

    //! Mutex used to control access to step
    mutex lock;
    //! Analytical step implementation
    std::auto_ptr<analytical_step> ptr;
    //! The current chunk to be processed
    unsigned current_chunk;
    //! (Ordered) vector of chunks to be processed
    std::priority_queue<data_chunk> queue;

private:
    //! Not implemented
    scheduler_step(const scheduler_step&);
    //! Not implemented
    scheduler_step& operator=(const scheduler_step&);
};


scheduler::scheduler()
  : m_steps()
  , m_running()
  , m_errors()
  , m_condition()
  , m_chunk_counter(0)
  , m_threads()
  , m_io_lock()
  , m_io_active(false)
{
}


scheduler::~scheduler()
{
    mutex_locker lock(m_running);

    for (pipeline::iterator it = m_steps.begin(); it != m_steps.end(); ++it) {
        delete *it;
    }

    m_steps.clear();
}


void scheduler::add_step(analytical_step* step)
{
    mutex_locker lock(m_running);
    if (!step) {
        throw std::invalid_argument("scheduler::scheduler: NULL not allowed");
    }

    m_steps.push_back(new scheduler_step(step));
}



bool scheduler::run(int nthreads)
{
    if (m_steps.empty()) {
        throw std::invalid_argument("pipeline must contain at least one step");
    } else if (nthreads <= 0) {
        throw std::invalid_argument("scheduler::run: nthreads <= 0");
    }

    mutex_locker lock(m_running);

    m_chunk_counter = 0;
    for (pipeline::iterator it = m_steps.begin(); it != m_steps.end(); ++it) {
        (*it)->reset();
    }

    for (unsigned task = 3 * nthreads; task; --task) {
        m_steps.front()->queue.push(data_chunk(data_chunk::value, m_chunk_counter++));
    }

    m_io_active = false;
    m_errors = !initialize_threads(nthreads - 1);

    // Signal for threads to start, or terminate in case of errors
    signal_threads();

    m_errors = !run_wrapper(this) || m_errors;
    m_errors = !join_threads() || m_errors;

    return !m_errors;
}


void* scheduler::run_wrapper(void* ptr)
{
    scheduler* sch = reinterpret_cast<scheduler*>(ptr);

    try {
        return sch->do_run();
    } catch (const thread_abort&) {
        // Error messaging is assumed to have been done by thrower
    } catch (const std::exception& error) {
        print_locker lock;
        std::cerr << "Error in thread:\n  " << error.what() << std::endl;
    } catch (...) {
        print_locker lock;
        std::cerr << "Unhandled exception in thread" << std::endl;
    }

    sch->m_errors = true;
    sch->signal_threads();

    return reinterpret_cast<void*>(false);
}

void* scheduler::do_run()
{
    // Wait to allow early termination in case of errors during setup
    m_condition.wait();

    pipeline::iterator starting_iterator = m_steps.begin();
    while (starting_iterator != m_steps.end() && !m_errors) {
        data_chunk chunk;

        bool did_work = false;
        for (pipeline::iterator it = starting_iterator; it != m_steps.end(); ++it) {
            scheduler_step& step = **it;

            {
                mutex_locker lock(step.lock);

                if (chunk.type != data_chunk::empty) {
                    step.queue.push(chunk);
                    chunk = data_chunk();
                } else if (step.queue.empty()) {
                    continue;
                }

                if (step.ptr->get_ordering() == analytical_step::ordered) {
                    const unsigned available_chunk = step.queue.top().counter;
                    if (step.current_chunk != available_chunk) {
                        continue;
                    }
                }

                if (step.queue.top().type == data_chunk::terminator) {
                    if (it == starting_iterator) {
                        // End-marker received; stop performing this task
                        starting_iterator++;
                        step.current_chunk++;
                        chunk = step.queue.top();
                        step.queue.pop();
                    }

                    // Signal threads waiting for this / the next terminator
                    m_condition.signal();
                    continue;
                }

                // Only one thread is allowed to do IO at any time
                if (step.ptr->file_io()) {
                    mutex_locker lock(m_io_lock);
                    if (m_io_active) {
                        continue;
                    }

                    m_io_active = true;
                }

                chunk = step.queue.top();
                step.queue.pop();
            }

            try {
                chunk.data = step.ptr->process(chunk.data);

                mutex_locker lock(step.lock);
                step.current_chunk++;
            } catch (const std::exception& error) {
                // m_io_active is intentionally not unset here
                throw;
            }

            if (step.ptr->file_io()) {
                mutex_locker lock(m_io_lock);
                m_io_active = false;
            }

            if (it + 1 == m_steps.end()) {
                // Last step; queue the next input, re-using the data object.
                scheduler_step& first_step = *m_steps.front();
                mutex_locker lock(first_step.lock);
                first_step.queue.push(data_chunk(data_chunk::value,
                                                 m_chunk_counter++,
                                                 chunk.data));
            } else if (!chunk.data) {
                if (it == m_steps.begin()) {
                    // First step returning NULL signals end of pipeline
                    chunk.type = data_chunk::terminator;
                    starting_iterator++;
                } else {
                    print_locker lock;
                    std::cerr << "Error in scheduler; step " << (it - m_steps.begin()) + 1
                              << "returned NULL; only step 1 is allowed to return NULL."
                              << std::endl;

                    throw thread_abort();
                }
            }

            did_work = true;
            m_condition.signal();
        }

        if (!did_work) {
            m_condition.wait();
        }
    }

    // Signal any waiting threads
    m_condition.signal();

    return reinterpret_cast<void*>(true);
}


bool scheduler::initialize_threads(int nthreads)
{
    if (!m_threads.empty()) {
        throw std::invalid_argument("scheduler::initialize_threads: threads must be empty");
    } else if (nthreads < 0) {
        throw std::invalid_argument("scheduler::initialize_threads: negative thread count");
    }

    try {
        for (int i = 0; i < nthreads; ++i) {
            m_threads.push_back(pthread_t());
            switch (pthread_create(&m_threads.back(), NULL, &run_wrapper, this)) {
                case 0:
                    break;

                case EAGAIN:
                    throw thread_error("pthread_create: insufficient resources to create thread");

                case EINVAL:
                    throw thread_error("pthread_create: invalid attributes");

                case EPERM:
                    throw thread_error("pthread_create: insufficient permissions");

                default:
                    throw thread_error("pthread_create: unknown error");
            }
        }
    } catch (const thread_error& error) {
        print_locker lock;
        std::cerr << "ERROR: " << error.what() << std::endl;

        m_threads.pop_back();
        return false;
    }

    return true;
}


void scheduler::signal_threads()
{
    // Signal the main and all other threads
    for (size_t i = 0; i < m_threads.size() + 1; ++i) {
        m_condition.signal();
    }
}


bool scheduler::join_threads()
{
    bool join_result = true;
    for (thread_vector::iterator it = m_threads.begin(); it != m_threads.end(); ++it) {
        void* run_result = NULL;
        const int join_error = pthread_join(*it, &run_result);

        if (join_error) {
            join_result = false;

            print_locker lock;
            switch (join_error) {
                case EINVAL:
                    std::cerr << "Error in pthread_join: invalid thread" << std::endl;
                    break;

                case ESRCH:
                    std::cerr << "Error in pthread_join: thread not joinable" << std::endl;
                    break;

                case EDEADLK:
                    std::cerr << "Error in pthread_join: deadlock detected" << std::endl;
                    break;

                default:
                    std::cerr << "Error in pthread_join: unknown error: " << join_error << std::endl;
            }
        } else {
            join_result &= static_cast<bool>(run_result);
        }
    }

    m_threads.clear();

    return join_result;
}


